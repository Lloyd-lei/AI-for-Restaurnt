#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OpenAI Realtime å®¢æˆ·ç«¯ - ç«¯åˆ°ç«¯è¯­éŸ³å¯¹è¯ï¼ˆæ”¯æŒ Function Callingï¼‰
"""

import asyncio
import websockets
import json
import pyaudio
import numpy as np
import os
from dotenv import load_dotenv
import signal
import sys
import time
import base64
from function_tools import FUNCTION_DEFINITIONS, execute_function
import threading

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# ============================================================
# ğŸ¯ é…ç½®æ¥å£ - åœ¨è¿™é‡Œä¿®æ”¹è®¾ç½®
# ============================================================

# OpenAI é…ç½®
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
REALTIME_API_URL = "wss://api.openai.com/v1/realtime"
MODEL = "gpt-4o-realtime-preview-2024-10-01"

# éŸ³é¢‘å‚æ•°ï¼ˆOpenAI Realtime API è¦æ±‚ï¼‰
SAMPLE_RATE = 24000  # OpenAI è¦æ±‚ 24kHz
CHANNELS = 1
CHUNK_SIZE = 1024
FORMAT = pyaudio.paInt16

# æœåŠ¡å™¨ç«¯ VAD å‚æ•°ï¼ˆOpenAI è‡ªåŠ¨æ£€æµ‹è¯­éŸ³ï¼‰
VAD_THRESHOLD = 0.5  # ğŸ¯ VAD æ•æ„Ÿåº¦ï¼ˆ0.0-1.0ï¼‰ï¼Œè¶Šå°è¶Šæ•æ„Ÿ
VAD_PREFIX_PADDING_MS = 300  # è¯­éŸ³å‰å¡«å……ï¼ˆæ¯«ç§’ï¼‰
VAD_SILENCE_DURATION_MS = 500  # ğŸ¯ é™éŸ³å¤šä¹…åç»“æŸï¼ˆæ¯«ç§’ï¼‰ï¼Œå»ºè®® 200-1000

# TTS å‚æ•°
TTS_VOICE = "shimmer"  # ğŸ¯ å¯é€‰: alloy, echo, fable, onyx, nova, shimmer

# ============================================================

class RealtimeClient:
    def __init__(self):
        self.ws = None
        self.audio = pyaudio.PyAudio()
        self.input_stream = None
        self.output_stream = None
        self.is_running = False
        self.is_ai_speaking = False
        self.session_id = None
        
        # æ‰“æ–­æ§åˆ¶
        self.interrupt_flag = False
        self.drop_audio_until_cancelled = False  # ä¸¢å¼ƒéŸ³é¢‘å¸§æ ‡å¿—
    
    async def connect(self):
        """è¿æ¥åˆ° OpenAI Realtime API"""
        headers = {
            "Authorization": f"Bearer {OPENAI_API_KEY}",
            "OpenAI-Beta": "realtime=v1"
        }
        
        url = f"{REALTIME_API_URL}?model={MODEL}"
        
        print("ğŸ”„ æ­£åœ¨è¿æ¥åˆ° OpenAI Realtime API...")
        self.ws = await websockets.connect(url, extra_headers=headers)
        print("âœ… å·²è¿æ¥åˆ° OpenAI Realtime API")
        
        await self.configure_session()
        
    async def configure_session(self):
        """é…ç½®ä¼šè¯å‚æ•°"""
        config = {
            "type": "session.update",
            "session": {
                "modalities": ["text", "audio"],
                "instructions": (
                    "ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„å¤šè¯­è¨€AIåŠ©æ‰‹ï¼Œåå«å°åŠ©æ‰‹ã€‚ä½ å¯ä»¥ï¼š\n"
                    "1. ç”¨æˆ·è¯´ä»€ä¹ˆè¯­è¨€ï¼Œä½ å°±ç”¨ä»€ä¹ˆè¯­è¨€å›å¤\n"
                    "2. æŸ¥è¯¢å¤©æ°”ä¿¡æ¯\n"
                    "3. æ¨èé¾™å‡¤æ¥¼ä¸­é¤å…çš„ç¾é£Ÿ\n"
                    "4. æœç´¢å’Œæ¨èä¹¦ç±\n"
                    "5. å½“ç”¨æˆ·æ˜ç¡®è¡¨ç¤ºè¦ç»“æŸå¯¹è¯æ—¶ï¼Œè°ƒç”¨ end_conversation å‡½æ•°\n\n"
                    "å›å¤é£æ ¼ï¼šç®€æ´ã€è‡ªç„¶ã€å‹å¥½ã€‚ä½¿ç”¨ function calling æ¥å¤„ç†å…·ä½“æŸ¥è¯¢ã€‚"
                ),
                "voice": TTS_VOICE,
                "input_audio_format": "pcm16",
                "output_audio_format": "pcm16",
                "input_audio_transcription": {
                    "model": "whisper-1"
                },
                "turn_detection": {  # ğŸ¯ å¯ç”¨æœåŠ¡å™¨ç«¯ VADï¼ˆè‡ªåŠ¨æ£€æµ‹è¯´è¯ï¼‰
                    "type": "server_vad",
                    "threshold": VAD_THRESHOLD,
                    "prefix_padding_ms": VAD_PREFIX_PADDING_MS,
                    "silence_duration_ms": VAD_SILENCE_DURATION_MS
                },
                "tools": FUNCTION_DEFINITIONS  # ğŸ¯ æ·»åŠ  function calling
            }
        }
        
        await self.ws.send(json.dumps(config))
        print(f"âš™ï¸  ä¼šè¯é…ç½®å·²å‘é€ï¼ˆTTS: {TTS_VOICE}ï¼ŒServer VAD å·²å¯ç”¨ï¼ŒFunctions: {len(FUNCTION_DEFINITIONS)}ä¸ªï¼‰")
        
    async def start_audio_input(self):
        """å¯åŠ¨éº¦å…‹é£è¾“å…¥å¹¶æµå¼å‘é€åˆ° OpenAI"""
        self.input_stream = self.audio.open(
            format=FORMAT,
            channels=CHANNELS,
            rate=SAMPLE_RATE,
            input=True,
            frames_per_buffer=CHUNK_SIZE
        )
        
        print("ğŸ™ï¸  éº¦å…‹é£å·²å¯åŠ¨ï¼Œç›´æ¥æµå¼ä¼ è¾“åˆ° OpenAIï¼ˆServer VAD è‡ªåŠ¨æ£€æµ‹ï¼‰...")
        
        while self.is_running:
            try:
                # è¯»å–éŸ³é¢‘
                audio_data = await asyncio.to_thread(
                    self.input_stream.read, CHUNK_SIZE, False
                )
                
                # ğŸ¯ ç›´æ¥å‘é€éŸ³é¢‘æµåˆ° OpenAIï¼ˆä¸åšæœ¬åœ°å¤„ç†ï¼‰
                if not self.is_ai_speaking:
                    # Base64 ç¼–ç 
                    audio_b64 = base64.b64encode(audio_data).decode('utf-8')
                    
                    # å‘é€éŸ³é¢‘å¸§
                    audio_msg = {
                        "type": "input_audio_buffer.append",
                        "audio": audio_b64
                    }
                    await self.ws.send(json.dumps(audio_msg))
                
                await asyncio.sleep(0.001)
                
            except Exception as e:
                if self.is_running:
                    print(f"âŒ éŸ³é¢‘è¾“å…¥é”™è¯¯: {e}")
                break
    
    async def _send_function_result(self, call_id, result):
        """å‘é€å‡½æ•°æ‰§è¡Œç»“æœç»™ OpenAI"""
        # é‡ç½®éŸ³é¢‘ä¸¢å¼ƒæ ‡å¿—ï¼Œå‡†å¤‡æ¥æ”¶æ–°çš„å“åº”
        self.drop_audio_until_cancelled = False
        
        message = {
            "type": "conversation.item.create",
            "item": {
                "type": "function_call_output",
                "call_id": call_id,
                "output": json.dumps(result, ensure_ascii=False)
            }
        }
        await self.ws.send(json.dumps(message))
        
        # è¯·æ±‚ AI ç»§ç»­å“åº”
        response_msg = {
            "type": "response.create"
        }
        await self.ws.send(json.dumps(response_msg))
        
    async def start_audio_output(self):
        """å¯åŠ¨éŸ³é¢‘è¾“å‡º"""
        self.output_stream = self.audio.open(
            format=FORMAT,
            channels=CHANNELS,
            rate=SAMPLE_RATE,  # 24kHz
            output=True,
            frames_per_buffer=4800
        )
        
        print("ğŸ”Š éŸ³é¢‘è¾“å‡ºå·²å¯åŠ¨ï¼ˆ24kHzï¼‰")
    
    async def keyboard_listener(self):
        """ç›‘å¬é”®ç›˜è¾“å…¥ï¼ˆæŒ‰å›è½¦æ‰“æ–­ï¼‰"""
        def listen_keyboard():
            while self.is_running:
                try:
                    input()  # ç­‰å¾…å›è½¦é”®
                    if self.is_ai_speaking:
                        self.interrupt_flag = True
                except:
                    break
        
        # åœ¨å•ç‹¬çš„çº¿ç¨‹ä¸­è¿è¡Œ
        thread = threading.Thread(target=listen_keyboard, daemon=True)
        thread.start()
        
        # æ£€æŸ¥æ‰“æ–­æ ‡å¿—
        while self.is_running:
            if self.interrupt_flag:
                print("\nâš¡ æ£€æµ‹åˆ°æ‰“æ–­ï¼ˆå›è½¦é”®ï¼‰ï¼Œç«‹å³åœæ­¢æ’­æ”¾")
                
                # ğŸ¯ 1. ç«‹å³è®¾ç½®æ ‡å¿—ï¼Œä¸¢å¼ƒåç»­éŸ³é¢‘å¸§ï¼ˆä¸ç­‰æœåŠ¡å™¨ç¡®è®¤ï¼‰
                self.drop_audio_until_cancelled = True
                self.is_ai_speaking = False
                
                # ğŸ¯ 2. ç«‹å³æ¸…ç©ºéŸ³é¢‘ç¼“å†²åŒºå¹¶é‡å¯æµ
                if self.output_stream:
                    try:
                        self.output_stream.stop_stream()
                        self.output_stream.close()
                        
                        # é‡æ–°åˆ›å»ºéŸ³é¢‘æµï¼ˆå½»åº•æ¸…ç©ºç¼“å†²åŒºï¼‰
                        self.output_stream = self.audio.open(
                            format=FORMAT,
                            channels=CHANNELS,
                            rate=SAMPLE_RATE,
                            output=True,
                            frames_per_buffer=4800
                        )
                        print("ğŸ”‡ éŸ³é¢‘ç¼“å†²åŒºå·²æ¸…ç©º")
                    except Exception as e:
                        print(f"âš ï¸  é‡ç½®éŸ³é¢‘æµ: {e}")
                
                # ğŸ¯ 3. å¼‚æ­¥å‘é€å–æ¶ˆæ¶ˆæ¯åˆ°æœåŠ¡å™¨ï¼ˆä¸é˜»å¡ï¼‰
                try:
                    cancel_msg = {
                        "type": "response.cancel"
                    }
                    await self.ws.send(json.dumps(cancel_msg))
                    print("ğŸ“¤ å·²å‘é€å–æ¶ˆè¯·æ±‚åˆ°æœåŠ¡å™¨ï¼ˆç­‰å¾…ç¡®è®¤ï¼‰")
                except Exception as e:
                    print(f"âŒ å‘é€å–æ¶ˆè¯·æ±‚å¤±è´¥: {e}")
                    # å³ä½¿å‘é€å¤±è´¥ï¼Œæœ¬åœ°ä¹Ÿå·²ç»åœæ­¢äº†
                    self.drop_audio_until_cancelled = False
                
                self.interrupt_flag = False
                print("ğŸ™ï¸  å·²æ¢å¤ç›‘å¬ï¼Œå¯ä»¥ç»§ç»­è¯´è¯...")
            
            await asyncio.sleep(0.05)  # æ›´å¿«çš„æ£€æŸ¥é¢‘ç‡ï¼ˆ50msï¼‰
        
    async def handle_messages(self):
        """å¤„ç†æ¥è‡ªæœåŠ¡å™¨çš„æ¶ˆæ¯"""
        try:
            async for message in self.ws:
                data = json.loads(message)
                event_type = data.get("type")
                
                if event_type == "session.created":
                    self.session_id = data.get("session", {}).get("id")
                    print(f"ğŸ“ ä¼šè¯å·²åˆ›å»º: {self.session_id}")
                
                elif event_type == "session.updated":
                    print("âœ… ä¼šè¯é…ç½®å·²æ›´æ–°")
                
                # ğŸ¯ è¯­éŸ³æ£€æµ‹äº‹ä»¶ï¼ˆServer VADï¼‰
                elif event_type == "input_audio_buffer.speech_started":
                    print("ğŸ—£ï¸  æ£€æµ‹åˆ°è¯­éŸ³è¾“å…¥...")
                
                elif event_type == "input_audio_buffer.speech_stopped":
                    print("ğŸ”‡ è¯­éŸ³è¾“å…¥ç»“æŸï¼ŒOpenAI æ­£åœ¨è¯†åˆ«...")
                
                elif event_type == "conversation.item.input_audio_transcription.completed":
                    # OpenAI è¯†åˆ«å®Œæˆ
                    transcript = data.get("transcript", "")
                    if transcript:
                        print(f"ğŸ“ ä½ è¯´: {transcript}")
                
                elif event_type == "input_audio_buffer.committed":
                    print("âœ… éŸ³é¢‘å·²æäº¤ï¼Œç­‰å¾… AI å›å¤...")
                
                elif event_type == "response.created":
                    print("ğŸ¤– AI å¼€å§‹ç”Ÿæˆå›å¤...")
                
                elif event_type == "response.done":
                    print("âœ… AI å›å¤å®Œæˆ\n")
                    self.is_ai_speaking = False
                
                elif event_type == "response.text.delta":
                    delta = data.get("delta", "")
                    print(delta, end="", flush=True)
                
                elif event_type == "response.text.done":
                    text = data.get("text", "")
                    if text:
                        print(f"\nğŸ’¬ AI: {text}")
                
                elif event_type == "response.audio.delta":
                    # ğŸ¯ å¦‚æœæ­£åœ¨ç­‰å¾…å–æ¶ˆç¡®è®¤ï¼Œä¸¢å¼ƒæ‰€æœ‰éŸ³é¢‘å¸§
                    if self.drop_audio_until_cancelled:
                        # é™é»˜ä¸¢å¼ƒï¼Œä¸æ’­æ”¾
                        continue
                    
                    self.is_ai_speaking = True
                    audio_b64 = data.get("delta", "")
                    if audio_b64 and self.output_stream:
                        audio_data = base64.b64decode(audio_b64)
                        try:
                            self.output_stream.write(audio_data)
                        except Exception as e:
                            # å¯èƒ½åœ¨é‡ç½®æµæ—¶å‡ºé”™ï¼Œå¿½ç•¥
                            pass
                
                elif event_type == "response.audio.done":
                    print("ğŸ”Š AI è¯­éŸ³æ’­æ”¾å®Œæˆ")
                    self.is_ai_speaking = False
                
                # ğŸ¯ Function call ç›¸å…³äº‹ä»¶
                elif event_type == "response.function_call_arguments.delta":
                    # Function å‚æ•°å¢é‡ï¼ˆå¯é€‰ï¼šæ˜¾ç¤ºå‚æ•°æ„å»ºè¿‡ç¨‹ï¼‰
                    pass
                
                elif event_type == "response.function_call_arguments.done":
                    # Function å‚æ•°æ¥æ”¶å®Œæˆ
                    call_id = data.get("call_id")
                    function_name = data.get("name")
                    arguments_str = data.get("arguments", "{}")
                    
                    print(f"\nğŸ”§ è°ƒç”¨å‡½æ•°: {function_name}")
                    print(f"ğŸ“‹ å‚æ•°: {arguments_str}")
                    
                    # æ‰§è¡Œå‡½æ•°
                    try:
                        arguments = json.loads(arguments_str)
                        result = execute_function(function_name, arguments)
                        
                        print(f"âœ… å‡½æ•°ç»“æœ: {json.dumps(result, ensure_ascii=False, indent=2)}")
                        
                        # ğŸ¯ ç‰¹æ®Šå¤„ç†ï¼šend_conversation
                        if function_name == "end_conversation":
                            print("\nğŸ‘‹ ç”¨æˆ·é€‰æ‹©ç»“æŸå¯¹è¯")
                            # å…ˆå‘é€å‡½æ•°ç»“æœï¼Œç„¶åé€€å‡º
                            await self._send_function_result(call_id, result)
                            await asyncio.sleep(2)  # ç­‰å¾… AI è¯´å®Œå†è§
                            self.is_running = False
                            return
                        
                        # å‘é€å‡½æ•°ç»“æœç»™ OpenAI
                        await self._send_function_result(call_id, result)
                        
                    except Exception as e:
                        print(f"âŒ å‡½æ•°æ‰§è¡Œå¤±è´¥: {e}")
                        error_result = {"error": str(e)}
                        await self._send_function_result(call_id, error_result)
                
                # ğŸ¯ å“åº”è¢«å–æ¶ˆï¼ˆæ‰“æ–­ï¼‰
                elif event_type == "response.cancelled":
                    print("âœ… æœåŠ¡å™¨ç¡®è®¤ï¼šå“åº”å·²å–æ¶ˆ")
                    self.is_ai_speaking = False
                    self.drop_audio_until_cancelled = False  # é‡ç½®ä¸¢å¼ƒæ ‡å¿—
                
                elif event_type == "error":
                    error = data.get("error", {})
                    error_msg = error.get('message', 'æœªçŸ¥é”™è¯¯')
                    print(f"âŒ é”™è¯¯: {error_msg}")
                    
                    # å¦‚æœæ˜¯å–æ¶ˆå¤±è´¥é”™è¯¯ï¼Œé‡ç½®éŸ³é¢‘ä¸¢å¼ƒæ ‡å¿—
                    if "Cancellation failed" in error_msg or "no active response" in error_msg:
                        self.drop_audio_until_cancelled = False
                
        except websockets.exceptions.ConnectionClosed:
            print("ğŸ”Œ è¿æ¥å·²å…³é—­")
        except Exception as e:
            print(f"âŒ æ¶ˆæ¯å¤„ç†é”™è¯¯: {e}")
            
    async def run(self):
        """è¿è¡Œå®¢æˆ·ç«¯"""
        try:
            # è¿æ¥æœåŠ¡å™¨
            await self.connect()
            
            # å¯åŠ¨éŸ³é¢‘è¾“å‡º
            await self.start_audio_output()
            
            self.is_running = True
            
            print("\n" + "="*60)
            print("ğŸ‰ OpenAI Realtime å®¢æˆ·ç«¯å·²å¯åŠ¨ï¼ˆç«¯åˆ°ç«¯è¯­éŸ³å¯¹è¯ï¼‰")
            print(f"ğŸ¤– æ¨¡å‹: {MODEL}")
            print(f"ğŸ—£ï¸  TTS è¯­éŸ³: {TTS_VOICE}")
            print(f"ğŸ™ï¸  Server VAD å·²å¯ç”¨ï¼ˆè‡ªåŠ¨æ£€æµ‹è¯­éŸ³ï¼‰")
            print(f"   - VAD é˜ˆå€¼: {VAD_THRESHOLD}")
            print(f"   - é™éŸ³æ£€æµ‹: {VAD_SILENCE_DURATION_MS}ms")
            print("ğŸŒ å¤šè¯­è¨€è‡ªåŠ¨è¯†åˆ«ï¼ˆOpenAI Whisperï¼‰")
            print("\nğŸ”§ å¯ç”¨åŠŸèƒ½:")
            print("  ğŸ“ æŸ¥å¤©æ°” - é—®ã€ŒåŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿã€")
            print("  ğŸœ æŸ¥èœå• - é—®ã€Œæœ‰ä»€ä¹ˆæ¨èçš„èœï¼Ÿã€ã€Œæœ‰ä¸è¾£çš„èœå—ï¼Ÿã€")
            print("  ğŸ“š æœä¹¦ç± - é—®ã€Œæ¨èç§‘å¹»å°è¯´ã€ã€Œåˆ˜æ…ˆæ¬£çš„ä¹¦ã€")
            print("  ğŸ‘‹ ç»“æŸå¯¹è¯ - è¯´ã€Œå†è§ã€ã€Œæ‹œæ‹œã€")
            print("\nğŸ’¡ æ“ä½œæç¤º:")
            print("  ğŸ¤ ç›´æ¥è¯´è¯ï¼ŒOpenAI è‡ªåŠ¨æ£€æµ‹å’Œè¯†åˆ«ï¼ˆæ— éœ€ç­‰å¾…ï¼‰")
            print("  âš¡ æŒ‰å›è½¦é”®å¯ä»¥æ‰“æ–­ AI è¯´è¯")
            print("  ğŸ›‘ æŒ‰ Ctrl+C é€€å‡º")
            print("="*60 + "\n")
            
            # è¿è¡Œï¼ˆæ·»åŠ é”®ç›˜ç›‘å¬ï¼‰
            await asyncio.gather(
                self.start_audio_input(),
                self.handle_messages(),
                self.keyboard_listener()
            )
            
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ æ­£åœ¨é€€å‡º...")
        except Exception as e:
            print(f"âŒ è¿è¡Œé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
        finally:
            await self.cleanup()
            
    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        self.is_running = False
        
        if self.input_stream:
            self.input_stream.stop_stream()
            self.input_stream.close()
            
        if self.output_stream:
            self.output_stream.stop_stream()
            self.output_stream.close()
            
        if self.audio:
            self.audio.terminate()
            
        if self.ws:
            await self.ws.close()
            
        print("âœ… èµ„æºå·²æ¸…ç†")

def signal_handler(sig, frame):
    """å¤„ç† Ctrl+C ä¿¡å·"""
    print("\n\nğŸ‘‹ æ”¶åˆ°é€€å‡ºä¿¡å·...")
    sys.exit(0)

async def main():
    """ä¸»å‡½æ•°"""
    if not OPENAI_API_KEY:
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ° OPENAI_API_KEY")
        print("è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®ä½ çš„ API Keyï¼Œæˆ–è€…åœ¨ä»£ç ä¸­ç›´æ¥é…ç½®")
        return
    
    print("ğŸš€ OpenAI Realtime å®¢æˆ·ç«¯ï¼ˆç«¯åˆ°ç«¯è¯­éŸ³å¯¹è¯ï¼‰")
    print(f"ğŸ“¦ ä½¿ç”¨æ¨¡å‹: {MODEL}")
    print("")
    
    signal.signal(signal.SIGINT, signal_handler)
    
    client = RealtimeClient()
    await client.run()

if __name__ == "__main__":
    asyncio.run(main())

